{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c3d1c7",
   "metadata": {
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# libraries import\n",
    "\n",
    "import whitebox\n",
    "import sys\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import Markdown, display, HTML\n",
    "import geopandas as gpd\n",
    "from geopandas import *\n",
    "from ipyleaflet import *\n",
    "from sidecar import Sidecar\n",
    "from ipywidgets import *\n",
    "from ipywidgets.embed import embed_data\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from osgeo import gdal\n",
    "from osgeo import ogr\n",
    "import folium\n",
    "from folium import raster_layers, plugins\n",
    "from folium.plugins import MeasureControl, MousePosition\n",
    "import tempfile, shutil, os\n",
    "import json\n",
    "import math\n",
    "\n",
    "from shapely import geometry, ops\n",
    "import time\n",
    "import shutil\n",
    "from shapely.wkt import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aeaa40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return true;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return true;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d04e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    \n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fedde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dir():\n",
    "    \n",
    "    fdialog2.default_path = fdialog.selected\n",
    "    fdialog2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619f1cc1",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def wkdchooser():\n",
    "    \n",
    "    global fdialog\n",
    "    \n",
    "    fdialog = FileChooser(\n",
    "        os.getcwd(),        \n",
    "        title='<b>Working directory</b> (select folder)',\n",
    "        show_hidden=False,\n",
    "        select_default=True,\n",
    "        use_dir_icons=True,\n",
    "        show_only_dirs=True\n",
    "    )\n",
    "    \n",
    "    display(fdialog)\n",
    "    \n",
    "    fdialog.register_callback(change_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f617b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activatebut1():\n",
    "    \n",
    "    if fdialog2.selected[-4:] == '.tif':\n",
    "        button1.disabled = False\n",
    "    else:\n",
    "        button1.disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efb5f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activatebut2():\n",
    "    \n",
    "    if button1.disabled == True:\n",
    "        button2.disabled = True\n",
    "    else:\n",
    "        button2.disabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3984b23",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def demchooser():\n",
    "    \n",
    "    global fdialog2\n",
    "    \n",
    "    fdialog2 = FileChooser(\n",
    "        os.getcwd(),       \n",
    "        title='<b>Input preprocessed dem</b> (select *.tif file)',\n",
    "        show_hidden=False,\n",
    "        select_default=True,\n",
    "        use_dir_icons=True,\n",
    "        show_only_dirs=False\n",
    "    )   \n",
    "    \n",
    "    display(fdialog2) \n",
    "    \n",
    "    fdialog2.register_callback(activatebut1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05819d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamthresh():\n",
    "    \n",
    "    global txt1\n",
    "    \n",
    "    streamthresh_def1 = 2000\n",
    "    \n",
    "    printmd('**Stream length threshold for basin generation:**')\n",
    "    txt1 = widgets.Text(value=str(streamthresh_def1))\n",
    "    \n",
    "    display(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c93c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basin_gen():\n",
    "    \n",
    "    global check0\n",
    "    \n",
    "    check0 = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Only basin generation (to confirm distribution)',\n",
    "        disabled=False,\n",
    "        indent=False\n",
    "    )\n",
    "    \n",
    "    display(check0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f3e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preliminary():\n",
    "    \n",
    "    global check1\n",
    "    \n",
    "    check1 = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Delete preliminary data',\n",
    "        disabled=False,\n",
    "        indent=False\n",
    "    )\n",
    "    \n",
    "    display(check1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "247b9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster():\n",
    "      \n",
    "    transform_raster()\n",
    "    HillShade()\n",
    "    \n",
    "    #Open raster file\n",
    "    driver=gdal.GetDriverByName('GTiff')\n",
    "    driver.Register() \n",
    "    ds = gdal.Open(wdir+'DEM_HS.tif') \n",
    "    if ds is None:\n",
    "        print('Could not open')      \n",
    "   \n",
    "    #Get coordinates, cols and rows\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    cols = ds.RasterXSize \n",
    "    rows = ds.RasterYSize \n",
    "    \n",
    "    #Get extent\n",
    "    xmin=geotransform[0]\n",
    "    ymax=geotransform[3]\n",
    "    xmax=xmin+cols*geotransform[1]\n",
    "    ymin=ymax+rows*geotransform[5]\n",
    "    \n",
    "    #Raster convert to array in numpy\n",
    "    bands = ds.RasterCount\n",
    "    band=ds.GetRasterBand(1)\n",
    "    dataset= band.ReadAsArray(0,0,cols,rows)\n",
    "    dataimage=dataset\n",
    "    dataimage[dataimage[:,:]==-340282346638528859811704183484516925440.000]=0 \n",
    "    \n",
    "    with out3:\n",
    "        display(\"raster visualization, wait please..\")\n",
    "\n",
    "    #Visualization in folium       \n",
    "    raster_layers.ImageOverlay(\n",
    "        image=dataimage,\n",
    "        name='DEM (hillshade)',\n",
    "        bounds=[[ymin, xmin], [ymax, xmax]],\n",
    "        colormap=lambda x: (0, 0, 1, x) #plasma, viridis, inferno, magma, cividis        \n",
    "    ).add_to(map1)\n",
    "    \n",
    "    print(\"raster_layer done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb48fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinValley(fid, p1, p2, step):\n",
    "    \n",
    "    global inter_valley_shp\n",
    "   \n",
    "    #searching the lower valley\n",
    "    sel21 = inter_valley_shp.loc[inter_valley_shp['point1'] == p2]   \n",
    "    \n",
    "    if sel21.empty:                     \n",
    "        return ()       \n",
    "    \n",
    "    else:\n",
    "        fid21 = sel21['FID'].iloc[0]        \n",
    "        current = inter_valley_shp.loc[inter_valley_shp['FID'] == fid]        \n",
    "        m_valley_sel = sel21['mValley'].iloc[0]       \n",
    "        \n",
    "        if m_valley_sel != 'yes':            \n",
    "            #azimuth range - to join another valley\n",
    "            st_a = int(current['aziDN']-50.0)\n",
    "            end_a = int(current['aziDN']+50.0)\n",
    "            sel_a = int(sel21['aziUP']) \n",
    "            \n",
    "            if st_a < 0: \n",
    "                st_a = st_a + 360\n",
    "                podminka = (sel_a in range(st_a, 360)) or (sel_a in range(0, end_a))\n",
    "            elif end_a > 360:\n",
    "                end_a = end_a - 360\n",
    "                podminka = (sel_a in range(st_a, 360)) or (sel_a in range(0, end_a))\n",
    "            else:            \n",
    "                podminka = sel_a in range(st_a, end_a)            \n",
    "\n",
    "            if podminka:\n",
    "                geom_current =current.geometry.iloc[0]\n",
    "                geom_sel = sel21.geometry.iloc[0]\n",
    "\n",
    "                multi_line = geometry.MultiLineString([geom_current, geom_sel])                \n",
    "                merged_line = ops.linemerge(multi_line)\n",
    "\n",
    "                gs_ml = GeoSeries(merged_line)\n",
    "                inter_valley_shp.loc[inter_valley_shp['FID'] == fid, 'geometry'] = gs_ml.values                \n",
    "                inter_valley_shp.loc[inter_valley_shp['FID'] == fid, 'DN_ELEV'] = float(sel21['DN_ELEV'])\n",
    "                inter_valley_shp.loc[inter_valley_shp['FID'] == fid, 'LENGTH'] = float(current['LENGTH']) + float(sel21['LENGTH'])\n",
    "                inter_valley_shp.loc[inter_valley_shp['FID'] == fid, 'AVG_SLOPE'] = -999    \n",
    "\n",
    "                p2new = sel21['point2'].iloc[0]  \n",
    "                inter_valley_shp.loc[inter_valley_shp['FID'] == fid, 'point2'] = p2new             \n",
    "\n",
    "                inter_valley_shp.loc[inter_valley_shp['FID'] == fid, 'pointMid'] = -999                \n",
    "                inter_valley_shp.loc[inter_valley_shp['FID'] == fid, 'aziDN'] = float(sel21['aziDN'])\n",
    "\n",
    "                inter_valley_shp.loc[inter_valley_shp['FID'] == fid21, 'delet'] = \"yes\"\n",
    "               \n",
    "                #one more time\n",
    "                step = step + 1\n",
    "                joinValley(fid, p1, p2new, step)\n",
    "            else:                  \n",
    "                if step == 1:\n",
    "                    additionalSourceZone(fid, p1)                \n",
    "                return ()\n",
    "        else:           \n",
    "            return ()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e5ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additionalSourceZone(fid, p1):   \n",
    "    \n",
    "    global inter_valley_shp\n",
    "    \n",
    "    global sourceBasin_list\n",
    "    global sourceValley_list \n",
    "    \n",
    "    global basins_shp\n",
    "   \n",
    "    #removing incorrectly added source zones\n",
    "    sourceBasin_list = sourceBasin_list[:-1]\n",
    "    sourceValley_list = sourceValley_list[:-1]    \n",
    "    \n",
    "    bas11 = sel11['BASIN'].iloc[0]   \n",
    "    fid_bas = sel11['FID'].iloc[0] \n",
    "    basins_shp.loc[basins_shp['VALUE'] == bas11, 'blind'] = 'yes'\n",
    "    inter_valley_shp.loc[inter_valley_shp['point1'] == p1, 'blind'] = 'yes'\n",
    "\n",
    "    bas_sel = basins_shp.loc[basins_shp['VALUE'] == bas11]\n",
    "    inter_sel = inter_valley_shp.loc[inter_valley_shp['point1'] == p1]\n",
    "    \n",
    "    #defining of new source zone\n",
    "\n",
    "    bas_sel_shp = tempPath + '/bas_sel.shp'\n",
    "    bas_sel.to_file(bas_sel_shp)               \n",
    "\n",
    "    inter_sel_shp = tempPath + '/inter_sel.shp'\n",
    "    inter_sel.to_file(inter_sel_shp)                \n",
    "\n",
    "    demOne_tif = tempPath + '/demOne.tif'                \n",
    "    #DEM clipping by one basin\n",
    "    wbt.clip_raster_to_polygon(\n",
    "        dem, \n",
    "        bas_sel_shp, \n",
    "        demOne_tif\n",
    "    )\n",
    "\n",
    "    quantileOne_tif = tempPath + '/quantileOne.tif'\n",
    "    #elevation splitting to 5 quartiles\n",
    "    wbt.quantiles(\n",
    "        demOne_tif, \n",
    "        quantileOne_tif, \n",
    "        num_quantiles=4\n",
    "    )\n",
    "\n",
    "    quantiles_shp = tempPath + '/quantiles.shp'\n",
    "    #quartile raster to polygon\n",
    "    wbt.raster_to_vector_polygons(\n",
    "        quantileOne_tif, \n",
    "        quantiles_shp\n",
    "    )\n",
    "\n",
    "    #quartile selection\n",
    "    quantiles2 = gpd.read_file(quantiles_shp)\n",
    "    quant = quantiles2.loc[quantiles2['VALUE'] == 1.0]\n",
    "    quant_shp = tempPath + '/quant.shp'\n",
    "    quant.to_file(quant_shp)  \n",
    "\n",
    "    quant_lines_shp = tempPath + '/quant_lines.shp'\n",
    "    #quartile polygon to line\n",
    "    wbt.polygons_to_lines(\n",
    "        quant_shp, \n",
    "        quant_lines_shp\n",
    "    )\n",
    "\n",
    "    pour_shp = tempPath + '/pour_point.shp'\n",
    "    #pour point definition by intersection of qurtile (line) and talweg line\n",
    "    wbt.line_intersections(\n",
    "        inter_sel_shp, \n",
    "        quant_lines_shp, \n",
    "        pour_shp\n",
    "    )\n",
    "\n",
    "    #upper point selection\n",
    "    points = gpd.read_file(pour_shp)\n",
    "    point = points.loc[points['FID'] == 1]\n",
    "    pour_shp2 = tempPath + '/pour.shp'\n",
    "    point.to_file(pour_shp2) \n",
    "    \n",
    "    \n",
    "    interOne_tiff = tempPath + '/interOne.tif'\n",
    "    #talweg line to  raster\n",
    "    wbt.vector_lines_to_raster(\n",
    "        inter_sel_shp, \n",
    "        interOne_tiff, \n",
    "        field=\"FID\", \n",
    "        nodata=True, \n",
    "        cell_size=None, \n",
    "        base=flow_acc     \n",
    "    )\n",
    "    \n",
    "    pour_shp3 = tempPath + '/pour_point3.shp'\n",
    "    #pour point moves to talweg\n",
    "    wbt.jenson_snap_pour_points(\n",
    "        pour_shp2, \n",
    "        interOne_tiff, \n",
    "        pour_shp3, \n",
    "        30.0\n",
    "    )\n",
    "    \n",
    "    d8_one_tif = tempPath +'/d8_one.tif'\n",
    "    #d8 pointer raster clip\n",
    "    wbt.clip_raster_to_polygon(\n",
    "        d8_pointer, \n",
    "        bas_sel_shp, \n",
    "        d8_one_tif\n",
    "    )\n",
    "    \n",
    "    watershed_tif = tempPath +'/watershed.tif'\n",
    "    #new watershed computation .. source zone\n",
    "    wbt.watershed(\n",
    "        d8_one_tif, \n",
    "        pour_shp3, \n",
    "        watershed_tif\n",
    "    )\n",
    "\n",
    "    sourceZone_shp = tempPath + '/sourceZone.shp'\n",
    "    #watershad raster to polygon ... source zone\n",
    "    wbt.raster_to_vector_polygons(\n",
    "        watershed_tif, \n",
    "        sourceZone_shp\n",
    "    )\n",
    "    sourceZone = gpd.read_file(sourceZone_shp)   \n",
    "    \n",
    "    # talweg of new source zone\n",
    "    sourceValley = gpd.clip(inter_sel, sourceZone)    \n",
    "\n",
    "    #adding of source zone and talweg to shps\n",
    "    sourceZone.loc[sourceZone['FID'] == 1, 'FID'] = fid_bas\n",
    "    sourceZone.loc[sourceZone['VALUE'] == 1.0, 'VALUE'] = bas11\n",
    "    sourceBasin_list = pd.concat([sourceBasin_list, sourceZone])\n",
    "    sourceValley_list = pd.concat([sourceValley_list, sourceValley])  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8499ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation():  \n",
    "    \n",
    "    global bas_path    \n",
    "\n",
    "    global inter_valley_shp\n",
    "    \n",
    "    global sourceBasin_list\n",
    "    global sourceValley_list\n",
    "    \n",
    "    global basins_shp\n",
    "    global sel11\n",
    "    \n",
    "    global tempPath\n",
    "    \n",
    "    global flow_acc\n",
    "    global d8_pointer\n",
    "      \n",
    "    flow_t = 3000    \n",
    "    \n",
    "    # D8 pointer (flow pointer grid)\n",
    "    d8_pointer = wdir +'flow_pointer_grid.tif'\n",
    "    wbt.d8_pointer(\n",
    "        dem, \n",
    "        d8_pointer, \n",
    "        esri_pntr=False\n",
    "    )  \n",
    "    \n",
    "    with out3:\n",
    "        display(\"flow pointer grid - done\")\n",
    "\n",
    "    # flow accumulation\n",
    "    flow_acc = wdir + 'flow_accum.tif'\n",
    "    wbt.d8_flow_accumulation(\n",
    "        d8_pointer, \n",
    "        flow_acc, \n",
    "        out_type=\"cells\", \n",
    "        log=False, \n",
    "        clip=False, \n",
    "        pntr=True, \n",
    "        esri_pntr=False\n",
    "    )\n",
    "    \n",
    "    with out3:\n",
    "        display(\"flow accumulation - done\")\n",
    "    \n",
    "    # STREAMS\n",
    "    streams = wdir +'streams.tif'\n",
    "    wbt.extract_streams(\n",
    "        flow_acc, \n",
    "        streams, \n",
    "        flow_t,\n",
    "        zero_background=False\n",
    "    )\n",
    "    #remove short streams\n",
    "    long_streams = wdir +'long_streams.tif'\n",
    "    wbt.remove_short_streams(\n",
    "        d8_pointer, \n",
    "        streams, \n",
    "        long_streams, \n",
    "        int(stream_t), \n",
    "        esri_pntr=False\n",
    "    )\n",
    "    \n",
    "    with out3:\n",
    "        display(\"streams - done\")\n",
    "    \n",
    "    # subbasins\n",
    "    subbasins = wdir +'basins' + stream_t + '.tif'\n",
    "    wbt.subbasins(\n",
    "        d8_pointer, \n",
    "        long_streams, \n",
    "        subbasins, \n",
    "        esri_pntr=False\n",
    "    )\n",
    "   \n",
    "    # subbasins to polygons\n",
    "    sub_pol =wdir +'basins_pol' + stream_t + '.shp'\n",
    "    wbt.raster_to_vector_polygons(subbasins, sub_pol)\n",
    "    \n",
    "    with out3:\n",
    "        display(\"basins - done\")\n",
    "    \n",
    "    \n",
    "    if bGen_only == False:\n",
    "        #--------------------------------------------------    \n",
    "        #--------------------------------------------------    \n",
    "        # longest flowpath\n",
    "        inter_valley = wdir + 'intersect_valley.shp'\n",
    "        wbt.longest_flowpath(\n",
    "            dem, \n",
    "            subbasins,\n",
    "            inter_valley\n",
    "        )   \n",
    "\n",
    "        with out3:\n",
    "            display(\"intersect_valley - done\")\n",
    "\n",
    "        #-------------------------------------------------------------------------------------    \n",
    "        #-------------------------------------------------------------------------------------   \n",
    "\n",
    "        inter_valley_shp = gpd.read_file(inter_valley)\n",
    "        inter_valley_shp = inter_valley_shp.assign(point1=\"\")\n",
    "        inter_valley_shp = inter_valley_shp.assign(pointMid=\"\")\n",
    "        inter_valley_shp = inter_valley_shp.assign(point2=\"\")\n",
    "        inter_valley_shp = inter_valley_shp.assign(aziUP=-999)\n",
    "        inter_valley_shp = inter_valley_shp.assign(aziDN=-999)\n",
    "        inter_valley_shp = inter_valley_shp.assign(slope=-999)\n",
    "        inter_valley_shp = inter_valley_shp.assign(eleDif=-999)\n",
    "\n",
    "        basins_shp = gpd.read_file(sub_pol)\n",
    "        basins_shp = basins_shp.assign(blind=\"no\")  \n",
    "\n",
    "        demRaster = rasterio.open(dem)\n",
    "\n",
    "        for i in np.arange(0,len(inter_valley_shp)):       \n",
    "            geom = inter_valley_shp['geometry'][i] \n",
    "\n",
    "            n_geom = len(geom.coords)\n",
    "            mid_i = int(n_geom/2)\n",
    "\n",
    "            #first and last point of the line\n",
    "            p1 = str(geom.coords[0])\n",
    "            pMid = str(geom.coords[mid_i])\n",
    "            p2 = str(geom.coords[-1]) \n",
    "            inter_valley_shp.loc[i, 'point1'] = p1\n",
    "            inter_valley_shp.loc[i, 'pointMid'] = pMid\n",
    "            inter_valley_shp.loc[i, 'point2'] = p2    \n",
    "\n",
    "            #azimuth of line        \n",
    "            x1 = float(p1[1:-1].split(\", \")[0])\n",
    "            y1 = float(p1[1:-1].split(\", \")[1])\n",
    "            xM = float(pMid[1:-1].split(\", \")[0])\n",
    "            yM = float(pMid[1:-1].split(\", \")[1])\n",
    "            x2 = float(p2[1:-1].split(\", \")[0])\n",
    "            y2 = float(p2[1:-1].split(\", \")[1])        \n",
    "\n",
    "            #up_elev\n",
    "            row1, col1 = demRaster.index(x1,y1)    \n",
    "            up_ele = demRaster.read(1)[row1,col1]\n",
    "            inter_valley_shp.loc[i, 'UP_ELEV'] = up_ele \n",
    "            #dn_elev\n",
    "            row2, col2 = demRaster.index(x2,y2)    \n",
    "            dn_ele = demRaster.read(1)[row2,col2] \n",
    "            inter_valley_shp.loc[i, 'DN_ELEV'] = dn_ele \n",
    "            #elevation difference\n",
    "            ele_dif = up_ele - dn_ele\n",
    "            inter_valley_shp.loc[i, 'eleDif'] = ele_dif \n",
    "\n",
    "            #azimuth 2x\n",
    "            azi_up = math.degrees(math.atan2((x1-xM),(y1-yM)))\n",
    "            azi_up = azi_up + 180\n",
    "            if azi_up == 360.00:\n",
    "                azi_up = 0.0            \n",
    "            inter_valley_shp.loc[i, 'aziUP'] = azi_up \n",
    "\n",
    "            azi_dn = math.degrees(math.atan2((xM-x2),(yM-y2)))\n",
    "            azi_dn = azi_dn + 180\n",
    "            if azi_dn == 360.00:\n",
    "                azi_dn = 0.0            \n",
    "            inter_valley_shp.loc[i, 'aziDN'] = azi_dn \n",
    "\n",
    "            #slope\n",
    "            dist= math.dist([x1, y1], [x2, y2])\n",
    "            d_ele = up_ele - dn_ele\n",
    "            slope = math.degrees(math.asin(d_ele/dist))\n",
    "            inter_valley_shp.loc[i, 'slope'] = slope \n",
    "\n",
    "        with out3:\n",
    "            display(\"talweg parameters calculation - done\")\n",
    "\n",
    "\n",
    "        # BORDER VALLEYS REMOVAL -----------------------------------------\n",
    "\n",
    "        #DEM mask\n",
    "        oneRaster = wdir + \"oneRaster.tif\"\n",
    "        wbt.greater_than(\n",
    "            dem, \n",
    "            0.0, \n",
    "            oneRaster\n",
    "        )\n",
    "\n",
    "        #DEM mask to polygon\n",
    "        one_shp = wdir + 'extent.shp'\n",
    "        wbt.raster_to_vector_polygons(\n",
    "            oneRaster, \n",
    "            one_shp\n",
    "        )\n",
    "\n",
    "        #boundary polygon to line\n",
    "        boundary_shp = wdir + 'boundary.shp'    \n",
    "        wbt.polygons_to_lines(\n",
    "            one_shp, \n",
    "            boundary_shp\n",
    "        )\n",
    "\n",
    "        boundary = gpd.read_file(boundary_shp)\n",
    "        boundary_geom = boundary.iloc[0].geometry\n",
    "        basins_shp = basins_shp.assign(out=\"no\")\n",
    "        inter_valley_shp = inter_valley_shp.assign(out=\"no\")\n",
    "\n",
    "        for i in np.arange(0,len(basins_shp)): \n",
    "\n",
    "            povodi = basins_shp.iloc[i]\n",
    "            povodi_geom = povodi.geometry\n",
    "\n",
    "            if boundary_geom.touches(povodi_geom) == True:\n",
    "                \n",
    "                povodiValue = povodi.VALUE\n",
    "                basins_shp.loc[basins_shp[\"VALUE\"]==povodiValue,\"out\"] = 'yes'          \n",
    "                inter_valley_shp.loc[inter_valley_shp[\"BASIN\"] == povodiValue, 'out'] = 'yes'\n",
    "\n",
    "        basins_shp = basins_shp.loc[basins_shp['out'] != 'yes']\n",
    "        inter_valley_shp = inter_valley_shp.loc[inter_valley_shp['out'] != 'yes']\n",
    "\n",
    "        with out3:\n",
    "            display(\"border valley detection - done\")\n",
    "\n",
    "\n",
    "        # BORDER VALLEYS REMOVAL -----------------------------------------  \n",
    "        # -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        # IDENTIFICATION OF MAIN VALLEYS --------------------------------------\n",
    "        inter_valley_shp = inter_valley_shp.assign(mValley=\"no\")\n",
    "        selMainValleys = inter_valley_shp.loc[inter_valley_shp['slope'] < 5].loc[inter_valley_shp['eleDif'] < 50]\n",
    "\n",
    "        while len(selMainValleys)>0:\n",
    "\n",
    "            fid = selMainValleys.iloc[0]['FID']\n",
    "            p2 = selMainValleys.iloc[0]['point2'] #lower point of valley\n",
    "\n",
    "            #marking as the main valley\n",
    "            selMainValleys.loc[selMainValleys['FID'] == fid, 'mValley'] = 'yes'\n",
    "            inter_valley_shp.loc[inter_valley_shp['FID'] == fid, 'mValley'] = 'yes'\n",
    "\n",
    "            #searching the lower valley\n",
    "            sel21_fid = inter_valley_shp.loc[inter_valley_shp['point1'] == p2]['FID']\n",
    "            while len(sel21_fid)>0:      \n",
    "                sel21_fid = int(sel21_fid)\n",
    "\n",
    "                mVal = inter_valley_shp.loc[inter_valley_shp['FID'] == sel21_fid, 'mValley']\n",
    "                mVal = mVal.iloc[0]\n",
    "\n",
    "                if mVal !='yes':\n",
    "\n",
    "                    selMainValleys.loc[selMainValleys['FID'] == sel21_fid, 'mValley'] = 'yes'\n",
    "                    inter_valley_shp.loc[inter_valley_shp['FID'] == sel21_fid, 'mValley'] = 'yes'\n",
    "\n",
    "                    #is there following valley?\n",
    "                    p2 = inter_valley_shp.loc[inter_valley_shp['FID'] == sel21_fid]['point2']\n",
    "                    p2 = p2.iloc[0]\n",
    "\n",
    "                    sel21_fid = inter_valley_shp.loc[inter_valley_shp['point1'] == p2]['FID']\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            #exclusion of already passed main valleys from the next cycle\n",
    "            selMainValleys = selMainValleys.loc[selMainValleys['mValley'] != 'yes']      \n",
    "\n",
    "        with out3:\n",
    "            display(\"main valleys - done\")\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------------------------------------------------------------------------------------\n",
    "        # blind valleys\n",
    "\n",
    "        # going through valleys up to down - joining (not main valleys)\n",
    "        inter_valley_shp = inter_valley_shp.assign(delet=\"no\")   \n",
    "        inter_valley_shp = inter_valley_shp.assign(blind=\"no\") \n",
    "        smallValleys = inter_valley_shp.loc[inter_valley_shp['mValley'] != 'yes']\n",
    "\n",
    "        #temporary folder\n",
    "        tempPath = wdir + \"temp\"\n",
    "        tempExist = os.path.exists(tempPath)\n",
    "        if not tempExist:\n",
    "            os.makedirs(tempPath)\n",
    "\n",
    "        with out3:\n",
    "                label_i = Label()\n",
    "                display(label_i)\n",
    "\n",
    "        sourceBasin_list = gpd.GeoDataFrame()\n",
    "        sourceValley_list = gpd.GeoDataFrame()\n",
    "\n",
    "        for i in np.arange(0,len(smallValleys)):\n",
    "\n",
    "            label_i.value = str(i) + \" / \" + str(len(smallValleys)-1)\n",
    "\n",
    "            fid = smallValleys.iloc[i]['FID']\n",
    "            p1 = smallValleys.iloc[i]['point1']\n",
    "            p2 = smallValleys.iloc[i]['point2']\n",
    "            delete = smallValleys.iloc[i]['delet']      \n",
    "\n",
    "            # is it blind valley?\n",
    "            sel12 = smallValleys.loc[smallValleys['point2'] == p1]\n",
    "\n",
    "            # valley is blind.. can I join the lower valley?\n",
    "            if sel12.empty and delete != 'yes':\n",
    "\n",
    "                #selected talweg\n",
    "                sel11 = inter_valley_shp.loc[inter_valley_shp['point1'] == p1]            \n",
    "\n",
    "                if sel11.empty:\n",
    "                    with out4:\n",
    "                        display('neni shoda - problem?') #that should not happen\n",
    "                else:                \n",
    "                    #middle valley, followed another lower one?                \n",
    "                    sel21 = smallValleys.loc[smallValleys['point1'] == p2]\n",
    "\n",
    "                    if sel21.empty:\n",
    "                        #not part of large valley ---------------------------------------   \n",
    "\n",
    "                        bas11 = sel11['BASIN'].iloc[0]  \n",
    "                        fid_bas = sel11['FID'].iloc[0] \n",
    "                        basins_shp.loc[basins_shp['VALUE'] == bas11, 'blind'] = 'yes'\n",
    "                        inter_valley_shp.loc[inter_valley_shp['point1'] == p1, 'blind'] = 'yes'\n",
    "\n",
    "                        bas_sel = basins_shp.loc[basins_shp['VALUE'] == bas11]\n",
    "                        inter_sel = inter_valley_shp.loc[inter_valley_shp['point1'] == p1]\n",
    "\n",
    "                        #source zone definition\n",
    "                        \n",
    "                        bas_sel_shp = tempPath + '/bas_sel.shp'\n",
    "                        bas_sel.to_file(bas_sel_shp)               \n",
    "\n",
    "                        inter_sel_shp = tempPath + '/inter_sel.shp'\n",
    "                        inter_sel.to_file(inter_sel_shp)                \n",
    "\n",
    "                        demOne_tif = tempPath + '/demOne.tif'                \n",
    "                        #DEM clipping by one basin\n",
    "                        wbt.clip_raster_to_polygon(\n",
    "                            dem, \n",
    "                            bas_sel_shp, \n",
    "                            demOne_tif\n",
    "                        )\n",
    "\n",
    "                        quantileOne_tif = tempPath + '/quantileOne.tif'\n",
    "                        #elevation splitting to 5 quartiles\n",
    "                        wbt.quantiles(\n",
    "                            demOne_tif, \n",
    "                            quantileOne_tif, \n",
    "                            num_quantiles=5\n",
    "                        )\n",
    "\n",
    "                        quantiles_shp = tempPath + '/quantiles.shp'\n",
    "                        #quartile raster to polygon\n",
    "                        wbt.raster_to_vector_polygons(\n",
    "                            quantileOne_tif, \n",
    "                            quantiles_shp\n",
    "                        )\n",
    "\n",
    "                        #quartile selection\n",
    "                        quantiles2 = gpd.read_file(quantiles_shp)\n",
    "                        quant = quantiles2.loc[quantiles2['VALUE'] == 1.0]\n",
    "                        quant_shp = tempPath + '/quant.shp'\n",
    "                        quant.to_file(quant_shp)  \n",
    "\n",
    "                        quant_lines_shp = tempPath + '/quant_lines.shp'\n",
    "                        #quartile polygon to line\n",
    "                        wbt.polygons_to_lines(\n",
    "                            quant_shp, \n",
    "                            quant_lines_shp\n",
    "                        )\n",
    "\n",
    "                        pour_shp = tempPath + '/pour_point.shp'\n",
    "                        #pour point definition by intersection of quartile (line) and talweg line\n",
    "                        wbt.line_intersections(\n",
    "                            inter_sel_shp, \n",
    "                            quant_lines_shp, \n",
    "                            pour_shp\n",
    "                        )\n",
    "\n",
    "                        #upper point selection\n",
    "                        points = gpd.read_file(pour_shp)\n",
    "                        point = points.loc[points['FID'] == 1]\n",
    "                        pour_shp2 = tempPath + '/pour.shp'\n",
    "                        point.to_file(pour_shp2) \n",
    "\n",
    "                        interOne_tiff = tempPath + '/interOne.tif'\n",
    "                        #talweg line to raster\n",
    "                        wbt.vector_lines_to_raster(\n",
    "                            inter_sel_shp, \n",
    "                            interOne_tiff, \n",
    "                            field=\"FID\", \n",
    "                            nodata=True, \n",
    "                            cell_size=None, \n",
    "                            base=flow_acc     \n",
    "                        )\n",
    "\n",
    "                        pour_shp3 = tempPath + '/pour_point3.shp'\n",
    "                        #pour point moves to talweg\n",
    "                        wbt.jenson_snap_pour_points(\n",
    "                            pour_shp2, \n",
    "                            interOne_tiff, \n",
    "                            pour_shp3, \n",
    "                            30.0\n",
    "                        )\n",
    "\n",
    "                        d8_one_tif = tempPath +'/d8_one.tif'\n",
    "                        #d8 pointer raster clip\n",
    "                        wbt.clip_raster_to_polygon(\n",
    "                            d8_pointer, \n",
    "                            bas_sel_shp, \n",
    "                            d8_one_tif\n",
    "                        )\n",
    "\n",
    "                        watershed_tif = tempPath +'/watershed.tif'\n",
    "                        #new watershed computation .. source zone\n",
    "                        wbt.watershed(\n",
    "                            d8_one_tif, \n",
    "                            pour_shp3, \n",
    "                            watershed_tif\n",
    "                        )\n",
    "\n",
    "                        sourceZone_shp = tempPath + '/sourceZone.shp'\n",
    "                        #watershed raster to polygon ... source zone\n",
    "                        wbt.raster_to_vector_polygons(\n",
    "                            watershed_tif, \n",
    "                            sourceZone_shp\n",
    "                        )\n",
    "                        sourceZone = gpd.read_file(sourceZone_shp)   \n",
    "\n",
    "                        # talweg of new source zone\n",
    "                        sourceValley = gpd.clip(inter_sel, sourceZone)\n",
    "\n",
    "                        #adding of source zone and rtalweg to shps\n",
    "                        sourceZone.loc[sourceZone['FID'] == 1, 'FID'] = fid_bas\n",
    "                        sourceZone.loc[sourceZone['VALUE'] == 1.0, 'VALUE'] = bas11\n",
    "                        sourceBasin_list = pd.concat([sourceBasin_list, sourceZone])\n",
    "                        sourceValley_list = pd.concat([sourceValley_list, sourceValley])         \n",
    "\n",
    "                    else:\n",
    "                        # part of large valley -----------------------------          \n",
    "\n",
    "                        bas11 = sel11['BASIN'].iloc[0]\n",
    "                        bas_sel2 = basins_shp.loc[basins_shp['VALUE'] == bas11]\n",
    "                        inter_sel2 = inter_valley_shp.loc[inter_valley_shp['FID'] == fid]\n",
    "\n",
    "                        sourceBasin_list = pd.concat([sourceBasin_list, bas_sel2])\n",
    "                        sourceValley_list = pd.concat([sourceValley_list, inter_sel2])  \n",
    "\n",
    "                        step = 1\n",
    "                        joinValley(fid, p1, p2, step) \n",
    "                        \n",
    "                    with out2:\n",
    "                        out2.clear_output()      \n",
    "\n",
    "        \n",
    "        sourceValley_list = sourceValley_list.assign(azi=-999)\n",
    "        sourceValley_list = sourceValley_list.assign(azi_st=-999)\n",
    "        \n",
    "        #recalculation of source valleys parameters\n",
    "        for i in np.arange(0,len(sourceValley_list)):\n",
    "\n",
    "            sv_geom = sourceValley_list.iloc[i]['geometry']    \n",
    "            sv_fid = sourceValley_list.iloc[i]['FID']     \n",
    "\n",
    "            if sv_geom.geom_type == 'MultiLineString':\n",
    "                sv_wkt = sv_geom.wkt\n",
    "                #multistring to linestring\n",
    "                line_wkt = sv_wkt[5:].replace(\"((\", \"(\").replace(\"),\",\",\").replace(\", (\",\", \").replace(\"))\",\")\")\n",
    "                line_geom = loads(line_wkt)\n",
    "                gs_line = GeoSeries(line_geom)\n",
    "\n",
    "                sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'geometry'] = gs_line.values\n",
    "                sv_geom = sourceValley_list.iloc[i]['geometry']\n",
    "\n",
    "            #new length\n",
    "            sv_len = sv_geom.length\n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'LENGTH'] = sv_len\n",
    "\n",
    "            n_geom = len(sv_geom.coords)\n",
    "            mid_i = int(n_geom/2)\n",
    "\n",
    "            #first and last point of the line\n",
    "            p1 = str(sv_geom.coords[0])\n",
    "            pMid = str(sv_geom.coords[mid_i])\n",
    "            p2 = str(sv_geom.coords[-1])     \n",
    "\n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'point1'] = p1\n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'pointMid'] = pMid\n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'point2'] = p2    \n",
    "\n",
    "            #azimuth of line        \n",
    "            x1 = float(p1[1:-1].split(\", \")[0])\n",
    "            y1 = float(p1[1:-1].split(\", \")[1])\n",
    "            xM = float(pMid[1:-1].split(\", \")[0])\n",
    "            yM = float(pMid[1:-1].split(\", \")[1])\n",
    "            x2 = float(p2[1:-1].split(\", \")[0])\n",
    "            y2 = float(p2[1:-1].split(\", \")[1])   \n",
    "\n",
    "            #up_elev\n",
    "            row1, col1 = demRaster.index(x1,y1)    \n",
    "            up_ele = demRaster.read(1)[row1,col1]\n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'UP_ELEV'] = up_ele \n",
    "            #dn_elev\n",
    "            row2, col2 = demRaster.index(x2,y2)    \n",
    "            dn_ele = demRaster.read(1)[row2,col2] \n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'DN_ELEV'] = dn_ele \n",
    "            #elevation difference\n",
    "            ele_dif = up_ele - dn_ele\n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'eleDif'] = ele_dif \n",
    "\n",
    "            #azimuth 2x\n",
    "            azi_up = math.degrees(math.atan2((x1-xM),(y1-yM)))\n",
    "            azi_up = azi_up + 180\n",
    "            if azi_up == 360.00:\n",
    "                azi_up = 0.0            \n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'aziUP'] = azi_up \n",
    "\n",
    "            azi_dn = math.degrees(math.atan2((xM-x2),(yM-y2)))\n",
    "            azi_dn = azi_dn + 180\n",
    "            if azi_dn == 360.00:\n",
    "                azi_dn = 0.0            \n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'aziDN'] = azi_dn \n",
    "            \n",
    "            #source zone talweg azimuth\n",
    "            azi = math.degrees(math.atan2((x2-x1),(y2-y1)))               \n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'azi'] = azi \n",
    "            if azi < 0.0:\n",
    "                azi_st = azi * (-1.0)\n",
    "            else:\n",
    "                azi_st = azi\n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'azi_st'] = azi_st \n",
    "            \n",
    "            #slope\n",
    "            dist= math.dist([x1, y1], [x2, y2])\n",
    "            d_ele = up_ele - dn_ele\n",
    "            slope = math.degrees(math.asin(d_ele/dist))\n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'slope'] = slope  \n",
    "            sourceValley_list.loc[sourceValley_list['FID'] == sv_fid, 'AVG_SLOPE'] = slope\n",
    "\n",
    "        with out3:\n",
    "            display(\"recalculation of source valleys parameters - done\")\n",
    "\n",
    "        \n",
    "        #removal of redudant columns\n",
    "        del sourceBasin_list['out'];del sourceBasin_list['blind']\n",
    "        #shp export\n",
    "        sourceBasin_shp = wdir+ 'sourceBasins.shp'\n",
    "        sourceBasin_list.to_file(sourceBasin_shp)\n",
    "        \n",
    "        #removal of redudant columns\n",
    "        del sourceValley_list['point1']; del sourceValley_list['pointMid']; del sourceValley_list['point2']; del sourceValley_list['aziUP']; del sourceValley_list['aziDN']; del sourceValley_list['out']; del sourceValley_list['delet']; del sourceValley_list['mValley']\n",
    "        #shp export        \n",
    "        sourceValley_shp = wdir+ 'sourceValleys.shp'\n",
    "        sourceValley_list.to_file(sourceValley_shp)\n",
    "\n",
    "        # deleting a temporary folder\n",
    "        if os.path.isdir(tempPath):\n",
    "            shutil.rmtree(tempPath)\n",
    "\n",
    "        final_inter = inter_valley_shp.loc[inter_valley_shp['delet'] != 'yes']\n",
    "        #parameters recalculation of other valleys\n",
    "        for i in np.arange(0,len(final_inter)): \n",
    "\n",
    "            fi_geom = final_inter.iloc[i]['geometry']    \n",
    "            fi_fid = final_inter.iloc[i]['FID'] \n",
    "\n",
    "            #new length\n",
    "            fi_len = fi_geom.length\n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'LENGTH'] = fi_len\n",
    "\n",
    "            n_geom = len(fi_geom.coords)\n",
    "            mid_i = int(n_geom/2)\n",
    "\n",
    "            #first and last point of the line\n",
    "            p1 = str(fi_geom.coords[0])\n",
    "            pMid = str(fi_geom.coords[mid_i])\n",
    "            p2 = str(fi_geom.coords[-1])\n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'point1'] = p1\n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'pointMid'] = pMid\n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'point2'] = p2    \n",
    "\n",
    "            #azimuth of line        \n",
    "            x1 = float(p1[1:-1].split(\", \")[0])\n",
    "            y1 = float(p1[1:-1].split(\", \")[1])\n",
    "            xM = float(pMid[1:-1].split(\", \")[0])\n",
    "            yM = float(pMid[1:-1].split(\", \")[1])\n",
    "            x2 = float(p2[1:-1].split(\", \")[0])\n",
    "            y2 = float(p2[1:-1].split(\", \")[1])        \n",
    "\n",
    "            #up_elev\n",
    "            row1, col1 = demRaster.index(x1,y1)    \n",
    "            up_ele = demRaster.read(1)[row1,col1]\n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'UP_ELEV'] = up_ele \n",
    "            #dn_elev\n",
    "            row2, col2 = demRaster.index(x2,y2)    \n",
    "            dn_ele = demRaster.read(1)[row2,col2] \n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'DN_ELEV'] = dn_ele \n",
    "            #elevation difference\n",
    "            ele_dif = up_ele - dn_ele\n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'eleDif'] = ele_dif \n",
    "\n",
    "            #azimuth 2x\n",
    "            azi_up = math.degrees(math.atan2((x1-xM),(y1-yM)))\n",
    "            azi_up = azi_up + 180\n",
    "            if azi_up == 360.00:\n",
    "                azi_up = 0.0            \n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'aziUP'] = azi_up \n",
    "\n",
    "            azi_dn = math.degrees(math.atan2((xM-x2),(yM-y2)))\n",
    "            azi_dn = azi_dn + 180\n",
    "            if azi_dn == 360.00:\n",
    "                azi_dn = 0.0            \n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'aziDN'] = azi_dn \n",
    "\n",
    "            #slope\n",
    "            dist= math.dist([x1, y1], [x2, y2])\n",
    "            d_ele = up_ele - dn_ele\n",
    "            slope = math.degrees(math.asin(d_ele/dist))\n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'slope'] = slope   \n",
    "            final_inter.loc[final_inter['FID'] == fi_fid, 'AVG_SLOPE'] = slope\n",
    "\n",
    "        with out3:\n",
    "            display(\"valley parameter recalculation - done\")\n",
    "            \n",
    "        with out2:\n",
    "                out2.clear_output()\n",
    "\n",
    "                \n",
    "        #removal of redudant columns\n",
    "        del final_inter['point1'];  del final_inter['pointMid'];  del final_inter['point2'];  del final_inter['aziUP'];  del final_inter['aziDN'];  del final_inter['out'];  del final_inter['delet']\n",
    "        #shp export\n",
    "        inter_valley2 = wdir + 'intersect_valley2.shp'\n",
    "        final_inter.to_file(inter_valley2) \n",
    "\n",
    "        #removal of redudant columns\n",
    "        del basins_shp['out']\n",
    "        #shp export\n",
    "        basins2 = wdir + 'basins2.shp'\n",
    "        basins_shp.to_file(basins2)         \n",
    "        \n",
    "   \n",
    "    #display on map\n",
    "    if bGen_only == True:\n",
    "        bas_path = sub_pol\n",
    "    else: \n",
    "        style_function2 = lambda x: {\"weight\":2, \n",
    "                                     'color':'#4292c6',                          \n",
    "                                     'fillOpacity': 1}\n",
    "        iv_shp =  wdir + 'intersect_valley2.shp'\n",
    "        iv_data = gpd.read_file(iv_shp)   \n",
    "        iv_data = iv_data.to_crs(\"EPSG:32638\")\n",
    "        folium.GeoJson(iv_data,\n",
    "                       style_function=style_function2, \n",
    "                        name='inter valley',\n",
    "                        control=True        \n",
    "                        ).add_to(map1)\n",
    "        \n",
    "        bas_path = basins2\n",
    "    bas_shp = gpd.read_file(bas_path)   \n",
    "    bas_shp = bas_shp.to_crs(\"EPSG:32638\")\n",
    "    bas_shp.to_file(bas_path)       \n",
    "    \n",
    "    #add basins shp to map\n",
    "    basins_gdf = gpd.read_file(bas_path).to_crs(\"EPSG:4326\")    \n",
    "    style = {'fillColor': 'none', \n",
    "              'color': '#FF1908', \n",
    "              'weight' : 1}    \n",
    "    folium.GeoJson(data=basins_gdf[\"geometry\"],\n",
    "                   name='basins_' + stream_t,\n",
    "                   style_function=lambda x:style\n",
    "                   ).add_to(map1)\n",
    "    \n",
    "    #add DEM to map    \n",
    "    raster()  \n",
    "    #display map\n",
    "    display_map()    \n",
    "    \n",
    "    driver = ogr.GetDriverByName(\"ESRI Shapefile\")    \n",
    "    #delete preliminary data\n",
    "    if delete_data == True:\n",
    "        os.remove(subbasins)\n",
    "        os.remove(flow_acc)\n",
    "        os.remove(d8_pointer)\n",
    "        os.remove(streams)\n",
    "        os.remove(long_streams)        \n",
    "        os.remove(output_raster)\n",
    "        os.remove(output_raster_HS)\n",
    "    if bGen_only == False:        \n",
    "        driver.DeleteDataSource(sub_pol)\n",
    "        driver.DeleteDataSource(inter_valley)\n",
    "        os.remove(oneRaster)\n",
    "        driver.DeleteDataSource(boundary_shp)          \n",
    "    \n",
    "    with out3:\n",
    "        printmd('**PROCESSING DONE**')\n",
    "        printmd('All results saved in: ' + wdir +\".\")\n",
    "        printmd('(If you need more detailed basin polygon, try to decrease stream lenght threshold (e.g. 1000).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81551674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_raster():\n",
    "    \n",
    "    global wdir\n",
    "    global output_raster\n",
    "\n",
    "    path=fdialog2.selected\n",
    "    path=path.replace(\"\\\\\", \"/\")\n",
    "    filename=path \n",
    "    input_raster=gdal.Open(filename)\n",
    "    output_name = filename.split(\"/\")[-1][0:-4]\n",
    "    output_raster=wdir+output_name+\"_TRANSFORMED.tif\"\n",
    "    warp=gdal.Warp(output_raster,input_raster,dstSRS='EPSG:4326')\n",
    "    warp=None # Closes the files\n",
    "    \n",
    "    with rasterio.open (output_raster) as r:\n",
    "        printmd(\"Coordinate system of raster: \") \n",
    "        print(r.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "747d89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HillShade():\n",
    "    \n",
    "    global output_raster_HS\n",
    "    \n",
    "    output_raster_HS = gdal.DEMProcessing(wdir+'DEM_HS.tif', \n",
    "                                          output_raster, \n",
    "                                          'hillshade', #slope, color-relief, TRI, TPI, roughness, hillshade\n",
    "                                          options=[], \n",
    "                                          azimuth=80, \n",
    "                                          altitude=300) \n",
    "    \n",
    "    output_raster_HS = wdir+'DEM_HS.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f25f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_map():\n",
    "    \n",
    "    # zoom to layers\n",
    "    map1.fit_bounds(map1.get_bounds(), padding=(20, 20))\n",
    "    \n",
    "    lc = folium.LayerControl(position='topleft')\n",
    "    lc.add_to(map1)\n",
    "            \n",
    "    with out4:\n",
    "        display(map1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86f108b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results():\n",
    "    \n",
    "    global out4    \n",
    "    \n",
    "    out4 = widgets.Output(layout={'border': '2px solid black'})\n",
    "    display(out4)       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f003798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing():\n",
    "    \n",
    "    global out2\n",
    "    out2 = widgets.Output(layout={'border': '2px solid black', 'height':'1000px'})\n",
    "    display(out2)\n",
    "    \n",
    "    with out2:\n",
    "        display('will be processed here ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66da8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg():\n",
    "    \n",
    "    global out3\n",
    "    \n",
    "    out3 = widgets.Output(layout={'border': '2px solid black', 'height':'550px'})\n",
    "    display(out3)\n",
    "    \n",
    "    with out3:\n",
    "        display('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44064dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation():\n",
    "    \n",
    "    global wbt\n",
    "    global wdir\n",
    "    global dem\n",
    "    global delete_data\n",
    "    global stream_t\n",
    "    global bGen_only\n",
    "    \n",
    "    wbt = whitebox.WhiteboxTools()\n",
    "    \n",
    "    #working directory\n",
    "    wdir = fdialog.selected\n",
    "    wdir = wdir.replace(\"\\\\\", \"/\")\n",
    "    wbt.work_dir = os.path.dirname(wdir)    \n",
    "    \n",
    "    #input dem\n",
    "    dem = fdialog2.selected\n",
    "    dem = dem.replace(\"\\\\\", \"/\")    \n",
    "    \n",
    "    #calculate only basins - not parameters\n",
    "    bGen_only = check0.value\n",
    "    \n",
    "    #delete preliminary data\n",
    "    delete_data = check1.value\n",
    "    \n",
    "    #stream length threshold for basin generation\n",
    "    stream_t = txt1.value\n",
    "    \n",
    "    with out2:\n",
    "        out2.clear_output()\n",
    "        calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08813b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button1_clicked(b):  \n",
    "    global map1\n",
    "    \n",
    "    with out3:\n",
    "        out3.clear_output()\n",
    "        printmd('computing ..')\n",
    "    with out4:\n",
    "        out4.clear_output()\n",
    "        \n",
    "    #Visualization in folium\n",
    "    \n",
    "    map1= folium.Map(control_scale=True).add_child(MeasureControl())\n",
    "\n",
    "    folium.TileLayer(\n",
    "        tiles=\"https://tiles.stadiamaps.com/tiles/stamen_terrain/{z}/{x}/{y}{r}.png\",\n",
    "        name='Stadia.StamenTerrain',\n",
    "        minZoom = 0,\n",
    "        maxZoom = 18,\n",
    "        attr='&copy; <a href=\"https://www.stadiamaps.com/\" target=\"_blank\">Stadia Maps</a> &copy; <a href=\"https://www.stamen.com/\" target=\"_blank\">Stamen Design</a> &copy; <a href=\"https://openmaptiles.org/\" target=\"_blank\">OpenMapTiles</a> &copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors'\n",
    "    ).add_to(map1)\n",
    "\n",
    "\n",
    "    folium.TileLayer(\n",
    "        tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "        name='Esri.WorldStreetMap',\n",
    "        attr='Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community'\n",
    "    ).add_to(map1)\n",
    "    \n",
    "    fs = plugins.Fullscreen(position='topright', \n",
    "                      title='Full Screen', \n",
    "                      title_cancel='Exit Full Screen', \n",
    "                      force_separate_button=False, \n",
    "                      )    \n",
    "    fs.add_to(map1)\n",
    "    \n",
    "    formatter = \"function(num) {return L.Util.formatNum(num, 5) + ' º ';};\"\n",
    "    \n",
    "    mp = plugins.MousePosition(\n",
    "                    position=\"topleft\",\n",
    "                    separator=\" | \",\n",
    "                    empty_string=\"Coordinates: __ | __\",\n",
    "                    lng_first=True,\n",
    "                    num_digits=20,\n",
    "                    prefix=\"Coordinates:\",\n",
    "                    lat_formatter=formatter,\n",
    "                    lng_formatter=formatter,\n",
    "                    )\n",
    "    mp.add_to(map1)\n",
    "        \n",
    "    preparation()\n",
    "\n",
    "def but1():\n",
    "    \n",
    "    global button1\n",
    "    button1 = widgets.Button(description=\"OK\", disabled=True)\n",
    "    display(button1)    \n",
    "    button1.on_click(on_button1_clicked)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1c483a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputsetting():\n",
    "    \n",
    "    out1 = widgets.Output(layout={'border': '2px solid black'})\n",
    "    display(out1)   \n",
    "    with out1:\n",
    "        wkdchooser()\n",
    "        demchooser()\n",
    "        streamthresh()\n",
    "        basin_gen()\n",
    "        preliminary()\n",
    "        but1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285154a5",
   "metadata": {},
   "source": [
    "# FLOW2024 - 1 - valley generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b79a4431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b21645cfea4583b50cf64dc51b7491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='2px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputsetting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5b3d726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05ae70889184732877fa81cc98a34a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='2px solid black', height='1000px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a08b9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9260ae6d4acf49cca5884f88a10068f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='2px solid black', height='550px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b01118d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21b4590a32e42e5b7e27707e5de1c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='2px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69802935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b635e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62ef55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
